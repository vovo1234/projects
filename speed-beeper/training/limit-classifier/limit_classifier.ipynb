{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quarterly-progressive",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "cv2 to load images<br>\n",
    "numpy to convert images into float arrays<br>\n",
    "tensorflow for training model framework<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perfect-purse",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-562de99df4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-berkeley",
   "metadata": {},
   "source": [
    "# Load and analyse ground truth\n",
    "View histogram on how many examples we have for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fossil-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-1', 442),\n",
      " ('-2', 1094),\n",
      " ('25', 2),\n",
      " ('30', 37),\n",
      " ('35', 605),\n",
      " ('40', 139),\n",
      " ('45', 426),\n",
      " ('50', 426),\n",
      " ('55', 263)]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def load_csv(path):\n",
    "    with open(path, 'r') as fs:\n",
    "        lines = fs.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [line.split(\",\") for line in lines]\n",
    "    columns = lines[0]\n",
    "    lines = lines[1:]\n",
    "    \n",
    "    return columns, lines\n",
    "\n",
    "def filter_columns(column_names, rows, new_columns):\n",
    "    column_indexes = [column_names.index(col) for col in new_columns]\n",
    "    new_rows = [[row[column_index] for column_index in column_indexes] for row in rows]\n",
    "    return new_rows\n",
    "\n",
    "# load ground truth\n",
    "dataset_path = \"../../dataset/\"\n",
    "truth_path = os.path.join(dataset_path, \"truth.csv\")\n",
    "column_names, rows = load_csv(truth_path)\n",
    "# print(column_names)\n",
    "\n",
    "# leave only speed_limit column\n",
    "new_columns = [\"file\", \"speed_limit\"]\n",
    "speed_limit_rows = filter_columns(column_names, rows, new_columns)\n",
    "\n",
    "# get speed limit values\n",
    "speed_limits = set([row[1] for row in speed_limit_rows])\n",
    "speed_limits = list(speed_limits)\n",
    "speed_limits.sort()\n",
    "\n",
    "# print histogram\n",
    "# -2 is for specified but unknows speed limits (marked as a cross in the image)\n",
    "# -1 if for un-specified speed limit roads\n",
    "hist = [0 for speed_limit in speed_limits]\n",
    "for row in speed_limit_rows:\n",
    "    hist[speed_limits.index(row[1])] += 1\n",
    "pprint.pprint(list(zip(speed_limits, hist)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-murder",
   "metadata": {},
   "source": [
    "# Load all images\n",
    "Load a small rectangle from each image, convert it to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "viral-exploration",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ece94bc86cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     speed_limit_images.append(image_path, 81, 36, 29, 18)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_speed_limit_subimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeed_limit_rows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m81\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-900def458580>\u001b[0m in \u001b[0;36mget_speed_limit_subimage\u001b[0;34m(image_path, x, y, w, h)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_speed_limit_subimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "def get_speed_limit_subimage(image_path, x, y, w, h):\n",
    "    image = cv2.imread(image_path)\n",
    "    return image\n",
    "       \n",
    "\n",
    "speed_limit_images = list(range(len(speed_limit_rows)))\n",
    "# for i, row in enumarate(speed_limit_rows):\n",
    "#     image_path = row[0]\n",
    "#     speed_limit_images.append(image_path, 81, 36, 29, 18)\n",
    "\n",
    "image = get_speed_limit_subimage(speed_limit_rows[0], 81, 36, 29, 18)\n",
    "cv2.imwrite(image, \"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "protecting-bermuda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d5bfb90e835b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"g4g.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imageio'"
     ]
    }
   ],
   "source": [
    "# Prepar\n",
    "import imageio as iio\n",
    "\n",
    "def loadImages(folder):\n",
    "    img = iio.imread(\"g4g.png\")\n",
    "\n",
    "    return []\n",
    "\n",
    "def loadTruth(folder):\n",
    "    return []\n",
    "\n",
    "def loadData(folder):\n",
    "    x = loadImages(folder)\n",
    "    y = loadTruth(folder)\n",
    " \n",
    "\n",
    "\n",
    "x, y = loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-milan",
   "metadata": {},
   "source": [
    "# Split dataset into train, cross-validation and test\n",
    "train is for training the model<br>\n",
    "cross-validation for adjusting model parameters<br>\n",
    "test is for blind testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-orlando",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
